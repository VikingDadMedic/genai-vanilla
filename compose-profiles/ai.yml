services:
  ollama:
    image: ${OLLAMA_IMAGE}
    container_name: ${PROJECT_NAME}-ollama
    restart: unless-stopped
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "${OLLAMA_PORT}:11434"
    networks:
      - backend-bridge-network

  ollama-pull:
    image: ${OLLAMA_PULL_IMAGE}
    container_name: ${PROJECT_NAME}-ollama-pull
    restart: "no"
    depends_on:
      supabase-db-init:
        condition: service_completed_successfully
      ollama:
        condition: service_started
    networks:
      - backend-bridge-network
    environment:
      PGHOST: supabase-db
      PGPORT: 5432
      PGDATABASE: ${SUPABASE_DB_NAME}
      PGUSER: ${SUPABASE_DB_USER}
      PGPASSWORD: ${SUPABASE_DB_PASSWORD}
      OLLAMA_HOST_URL: http://ollama:11434
    volumes:
      - ./ollama-pull/scripts:/scripts
    entrypoint: ["/scripts/pull.sh"]

  comfyui-init:
    image: ${COMFYUI_INIT_IMAGE}
    container_name: ${PROJECT_NAME}-comfyui-init
    restart: "no"
    depends_on:
      supabase-db-init:
        condition: service_completed_successfully
      ollama-pull:
        condition: service_completed_successfully
    networks:
      - backend-bridge-network
    environment:
      PGHOST: supabase-db
      PGPORT: 5432
      PGDATABASE: ${SUPABASE_DB_NAME}
      PGUSER: ${SUPABASE_DB_USER}
      PGPASSWORD: ${SUPABASE_DB_PASSWORD}
      COMFYUI_MODELS_PATH: /models
    volumes:
      - ./comfyui-init/scripts:/scripts
      - comfyui-models:/models
    entrypoint: ["/scripts/download_models.sh"]

  local-deep-researcher:
    build:
      context: ./local-deep-researcher
      args:
        BASE_IMAGE: ${LOCAL_DEEP_RESEARCHER_IMAGE}
    container_name: ${PROJECT_NAME}-local-deep-researcher
    restart: unless-stopped
    depends_on:
      supabase-db-init:
        condition: service_completed_successfully
      ollama-pull:
        condition: service_completed_successfully
      searxng:
        condition: service_healthy
    environment:
      # Database connection for LLM config
      DATABASE_URL: postgresql://${SUPABASE_DB_USER}:${SUPABASE_DB_PASSWORD}@supabase-db:5432/${SUPABASE_DB_NAME}
      # Ollama connection (containerized)
      OLLAMA_BASE_URL: http://ollama:11434
      # Search configuration
      SEARCH_API: ${LOCAL_DEEP_RESEARCHER_SEARCH_API:-searxng}
      SEARXNG_URL: http://searxng:8080
      MAX_WEB_RESEARCH_LOOPS: ${LOCAL_DEEP_RESEARCHER_LOOPS:-3}
    ports:
      - "${LOCAL_DEEP_RESEARCHER_PORT}:2024"
    volumes:
      - local-deep-researcher-data:/app/data
    networks:
      - backend-bridge-network

  searxng:
    image: ${SEARXNG_IMAGE}
    container_name: ${PROJECT_NAME}-searxng
    restart: unless-stopped
    networks:
      - backend-bridge-network
    ports:
      - "${SEARXNG_PORT}:8080"
    volumes:
      - ./searxng/config:/etc/searxng:rw
      - searxng-data:/var/cache/searxng
    environment:
      - SEARXNG_BASE_URL=http://localhost:${SEARXNG_PORT}
      - SEARXNG_SECRET=${SEARXNG_SECRET}
      - FORCE_OWNERSHIP=1
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    depends_on:
      supabase-db-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy

  n8n:
    image: ${N8N_IMAGE}
    container_name: ${PROJECT_NAME}-n8n
    restart: unless-stopped
    depends_on:
      supabase-db-init:
        condition: service_completed_successfully
      ollama-pull:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    environment:
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: supabase-db
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: ${SUPABASE_DB_NAME}
      DB_POSTGRESDB_USER: ${SUPABASE_DB_USER}
      DB_POSTGRESDB_PASSWORD: ${SUPABASE_DB_PASSWORD}
      DB_POSTGRESDB_SCHEMA: n8n
      DB_SCHEMA: n8n
      N8N_HOST: n8n.localhost
      N8N_PORT: 5678
      N8N_PROTOCOL: ${N8N_PROTOCOL:-http}
      N8N_PROXY_HOPS: 1
      N8N_PUSH_BACKEND: websocket
      VUE_APP_URL_BASE_API: http://n8n.localhost:${KONG_HTTP_PORT}/
      GENERIC_TIMEZONE: ${TZ:-UTC}
      N8N_EDITOR_BASE_URL: http://n8n.localhost:${KONG_HTTP_PORT}
      N8N_ALLOW_CONNECTIONS_FROM: http://n8n.localhost:${KONG_HTTP_PORT}
      WEBHOOK_URL: http://n8n.localhost:${KONG_HTTP_PORT}/
      NODE_ENV: production
      N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY}
      N8N_AUTH_ENABLED: ${N8N_AUTH_ENABLED:-true}
      N8N_BASIC_AUTH_ACTIVE: ${N8N_BASIC_AUTH_ACTIVE:-true}
      N8N_BASIC_AUTH_USER: ${N8N_BASIC_AUTH_USER}
      N8N_BASIC_AUTH_PASSWORD: ${N8N_BASIC_AUTH_PASSWORD}
      N8N_SECURE_COOKIE: false
      N8N_RUNNERS_ENABLED: true
      N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS: true
      N8N_COMMUNITY_PACKAGES_ENABLED: ${N8N_COMMUNITY_PACKAGES_ENABLED:-true}
      N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE: ${N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE:-true}
      NODE_OPTIONS: --max_old_space_size=512
      EXECUTIONS_MODE: ${N8N_EXECUTIONS_MODE:-queue}
      QUEUE_BULL_REDIS_HOST: redis
      QUEUE_BULL_REDIS_PORT: 6379
      QUEUE_BULL_REDIS_PASSWORD: ${REDIS_PASSWORD}
      QUEUE_BULL_REDIS_DB: 0
    ports:
      - "${N8N_PORT}:5678"
    volumes:
      - n8n-data:/home/node/.n8n
    networks:
      - backend-bridge-network

  n8n-init:
    image: ${N8N_INIT_IMAGE:-alpine:latest}
    container_name: ${PROJECT_NAME}-n8n-init
    restart: "no"
    depends_on:
      n8n:
        condition: service_started
    environment:
      N8N_HOST: n8n
      N8N_PORT: 5678
      N8N_INIT_NODES: ${N8N_INIT_NODES:-n8n-nodes-comfyui,@ksc1234/n8n-nodes-comfyui-image-to-image,n8n-nodes-mcp}
    volumes:
      - ./n8n-init/scripts:/scripts
      - ./n8n-init/config:/config
      - n8n-data:/n8n-data
    networks:
      - backend-bridge-network
    entrypoint: ["/scripts/install-nodes.sh"]

  comfyui:
    image: ${COMFYUI_IMAGE}
    platform: ${COMFYUI_PLATFORM:-linux/amd64}
    container_name: ${PROJECT_NAME}-comfyui
    restart: unless-stopped
    depends_on:
      supabase-db-init:
        condition: service_completed_successfully
      ollama-pull:
        condition: service_completed_successfully
      comfyui-init:
        condition: service_completed_successfully
      supabase-storage:
        condition: service_started
      redis:
        condition: service_started
    environment:
      - COMFYUI_ARGS=${COMFYUI_ARGS:---listen --cpu}
      - AUTO_UPDATE=${COMFYUI_AUTO_UPDATE:-false}
      - COMFYUI_PORT_HOST=8188
      - WEB_ENABLE_AUTH=false
      - ENABLE_QUICKTUNNEL=false
      - SERVERLESS=false
      - SUPABASE_URL=${COMFYUI_KONG_URL:-http://kong-api-gateway:8000}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - SUPABASE_STORAGE_BUCKET=${COMFYUI_STORAGE_BUCKET:-comfyui-images}
      - COMFYUI_UPLOAD_TO_SUPABASE=${COMFYUI_UPLOAD_TO_SUPABASE:-true}
    ports:
      - "${COMFYUI_PORT}:18188"
    volumes:
      - comfyui-models:/opt/ComfyUI/models
      - comfyui-output:/opt/ComfyUI/output
      - comfyui-input:/opt/ComfyUI/input
      - comfyui-custom-nodes:/opt/ComfyUI/custom_nodes
    networks:
      - backend-bridge-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:18188/system_stats"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    labels:
      - "com.genai.service=image-generation"
      - "com.genai.category=ai"
      - "com.genai.dependencies=ollama,supabase-storage"

volumes:
  ollama-data:
  local-deep-researcher-data:
  searxng-data:
  n8n-data:
  comfyui-models:
  comfyui-output:
  comfyui-input:
  comfyui-custom-nodes:
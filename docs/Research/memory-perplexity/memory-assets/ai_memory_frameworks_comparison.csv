Framework,Architecture_Type,Storage_Backend,Memory_Types,Benchmark_Accuracy,Latency_Performance,Cost_Optimization,Temporal_Awareness,Search_Capabilities,Real_Time_Updates,API_Approach,Framework_Integration,Deployment_Options,Primary_Focus,Target_Applications,Multi_Tenant_Support,Open_Source_License,Maturity_Level,Community_Size
Mem0,Multi-level memory (user/session/agent),"Vector DB (Qdrant), SQL, NoSQL","Long-term, Short-term, Semantic, Episodic",26% improvement over OpenAI (LLM-as-Judge),91% lower p95 latency vs full-context,90% token cost savings,Limited temporal tracking,"Semantic search, vector similarity",Dynamic extraction and consolidation,"REST API, Python/JS SDKs","LangChain, AutoGen, Embedchain","Self-hosted, Managed service",General AI memory layer,"Customer support, Healthcare, Learning",Yes (user/session isolation),Apache 2.0,"Production-ready, Research paper",Large GitHub community
memU,Autonomous Memory Agent + File System,Knowledge Graph + Memory Files,"Organized, Linked, Evolved, Prioritized",92% accuracy (Locomo benchmark),Not specified,90% cost reduction,Memory evolution and aging,"Semantic, hybrid, contextual retrieval",Autonomous memory management,"Python client, Cloud API",AI companion focused,"Cloud, Enterprise, Community (planned)",AI companion specialization,"AI companions, Role-playing, Tutors",Yes (companion-specific),Open source,"Emerging, Community building",Growing Discord community
Memori,Multi-agent memory capture/analysis,SQL (SQLite/PostgreSQL/MySQL),"Conscious (short-term), Auto (long-term), Combined",Not specified in sources,Sub-second retrieval,Not specified,Not explicitly mentioned,Intelligent search and recall,Automatic memory capture,Python SDK (memorisdk),"LangChain, Agno, CrewAI","Self-hosted, GibsonAI infrastructure",AI agent memory engine,"Multi-agent systems, Workflows",Yes (user/agent isolation),Apache 2.0,"Production-ready, GibsonAI backed","Discord community, GitHub"
Zep/Graphiti,Temporal Knowledge Graph,Neo4j Knowledge Graph,"Semantic, Episodic, Entity, Community","94.8% DMR, 18.5% improvement LongMemEval","90% latency reduction, <100ms queries",98% token reduction (2% vs baseline),Bi-temporal model (event/ingestion time),Hybrid: semantic + BM25 + graph traversal,Real-time incremental updates,"REST API, Python/TypeScript/Go SDKs","LangChain, AutoGen, frameworks","Self-hosted, Zep Cloud",Enterprise agent memory,"Enterprise agents, Business data",Yes (enterprise multi-tenant),Apache 2.0 (Graphiti),"Production-ready, Academic validation","Established, Enterprise focus"
